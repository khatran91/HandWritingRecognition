{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vf4KUYgnghxg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyCp3fhS2phFKLyhWDVGSx7OjJU35d2jWK8\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------ Colab cell: OCR with Gemini Pro Vision (Updated) ------------\n",
        "!pip install --quiet --upgrade google-generativeai pillow\n",
        "\n",
        "import os, io, base64\n",
        "from PIL import Image\n",
        "import google.generativeai as genai\n",
        "\n",
        "# 1️⃣  ***Make sure your key is in env, e.g. os.environ[\"GEMINI_API_KEY\"] = \"...\"***\n",
        "\n",
        "# -------- helper: load image and convert to base‑64 --------------\n",
        "def encode_image_to_base64(path: str) -> str:\n",
        "    with Image.open(path) as img:\n",
        "        buf = io.BytesIO()\n",
        "        img.save(buf, format=\"PNG\")       # lossless for best OCR\n",
        "        return base64.b64encode(buf.getvalue()).decode()\n",
        "\n",
        "# -------- core OCR function using Gemini 1.5 Flash -------------\n",
        "def gemini_extract_text(image_path: str) -> str:\n",
        "    if \"GEMINI_API_KEY\" not in os.environ:\n",
        "        raise ValueError(\"Set GEMINI_API_KEY first: os.environ['GEMINI_API_KEY'] = 'YOUR_KEY'\")\n",
        "\n",
        "    genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "    # Build the request\n",
        "    prompt = \"Transcribe every readable character from this image. Return only the text.\"\n",
        "    image_b64 = encode_image_to_base64(image_path)\n",
        "\n",
        "    response = model.generate_content(\n",
        "        [\n",
        "            prompt,\n",
        "            {\n",
        "                \"mime_type\": \"image/png\",\n",
        "                \"data\": image_b64,\n",
        "            },\n",
        "        ],\n",
        "        generation_config={\"temperature\":0.0, \"max_output_tokens\":1024},\n",
        "    )\n",
        "\n",
        "    return response.text.strip()\n",
        "\n",
        "# -------- demo ---------------------------------------------------\n",
        "img_path = \"/content/image1.jpg\"   # <-- change to your uploaded file\n",
        "print(\"Extracted text:\\n\" + \"-\"*40)\n",
        "print(gemini_extract_text(img_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "sqFHAz3Dgl8c",
        "outputId": "5767695f-a803-4a04-f83c-9d4fdcda8feb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted text:\n",
            "----------------------------------------\n",
            "My name is Erin Fish. I am taking\n",
            "this course to improve my handwriting\n",
            "so I can enjoy writing in my journals\n",
            "again. As it stands now I find my\n",
            "handwriting to be ununiformed\n",
            "and unattractive. I would like my\n",
            "free hand to flow much more\n",
            "smoothly and as effortlessly as\n",
            "possible.\n"
          ]
        }
      ]
    }
  ]
}